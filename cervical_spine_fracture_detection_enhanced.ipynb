{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOucwNkeHpAzNsviqMfrVYT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sajjkavinda/cervical-spine-fracture-detection/blob/enhanced/cervical_spine_fracture_detection_enhanced.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y gdcm python-gdcm pydicom pylibjpeg pylibjpeg-libjpeg pylibjpeg-openjpeg --quiet\n",
        "!pip install pydicom pylibjpeg pylibjpeg-libjpeg pylibjpeg-openjpeg --quiet\n",
        "!pip install opencv-python matplotlib tqdm --quiet\n",
        "!pip install pandas scikit-learn matplotlib tqdm --quiet\n",
        "!pip install torch torchvision torchaudio --quiet"
      ],
      "metadata": {
        "id": "qVisTd0fGKqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "Ad9qImw3GQfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q \"/content/drive/MyDrive/Dataset-RSNA/rsna_subset.zip\" -d \"/content/rsna_subset\" && echo \"Unzip completed successfully!\""
      ],
      "metadata": {
        "id": "jEUMp1qPGOeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import pydicom\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "BYmVvAyRG9NZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import pydicom\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Paths\n",
        "DICOM_ROOT = \"/content/rsna_subset_images\"\n",
        "IMAGE_ROOT = \"/content/rsna_png_images\"\n",
        "os.makedirs(IMAGE_ROOT, exist_ok=True)\n",
        "\n",
        "# Convert DICOM to PNG\n",
        "for study_uid in tqdm(os.listdir(DICOM_ROOT)):\n",
        "    study_path = os.path.join(DICOM_ROOT, study_uid)\n",
        "    if not os.path.isdir(study_path):\n",
        "        continue\n",
        "    png_folder = os.path.join(IMAGE_ROOT, study_uid)\n",
        "    os.makedirs(png_folder, exist_ok=True)\n",
        "\n",
        "    dicom_files = [f for f in os.listdir(study_path) if f.lower().endswith(\".dcm\")]\n",
        "    if not dicom_files:\n",
        "        os.rmdir(png_folder)\n",
        "        continue\n",
        "\n",
        "    # Take up to 3 middle slices\n",
        "    dicom_files = sorted(dicom_files)\n",
        "    mid = len(dicom_files) // 2\n",
        "    start = max(0, mid-1)\n",
        "    selected = dicom_files[start:start+3]\n",
        "\n",
        "    for f in selected:\n",
        "        dicom_path = os.path.join(study_path, f)\n",
        "        png_path = os.path.join(png_folder, f.replace(\".dcm\",\".png\"))\n",
        "        try:\n",
        "            dcm = pydicom.dcmread(dicom_path)\n",
        "            img = dcm.pixel_array\n",
        "            img = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
        "            cv2.imwrite(png_path, img)\n",
        "        except Exception as e:\n",
        "            print(f\"Failed {dicom_path}: {e}\")\n",
        "\n",
        "print(\"All DICOMs converted. Only folders with PNGs remain.\")\n",
        "\n",
        "# Verify dataset\n",
        "studies_with_images = [d for d in os.listdir(IMAGE_ROOT) if os.path.isdir(os.path.join(IMAGE_ROOT, d)) and len(os.listdir(os.path.join(IMAGE_ROOT, d)))>0]\n",
        "print(\"Studies with images:\", len(studies_with_images))\n"
      ],
      "metadata": {
        "id": "qU7V30y9F9rh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WY0omAVqF7Ad",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import os, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from torchvision.models import (resnet18, ResNet18_Weights)\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, confusion_matrix\n",
        "\n",
        "# Paths & config\n",
        "CSV_DIR = \"/content/subset_csv\"\n",
        "IMAGE_ROOT = \"/content/rsna_png_images\"\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "NUM_EPOCHS = 6\n",
        "LR = 1e-4\n",
        "NUM_WORKERS = 2\n",
        "RANDOM_SEED = 42\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)\n",
        "\n",
        "# Load CSVs\n",
        "train_df = pd.read_csv(os.path.join(CSV_DIR,\"train.csv\"))\n",
        "val_df   = pd.read_csv(os.path.join(CSV_DIR,\"val.csv\"))\n",
        "test_df  = pd.read_csv(os.path.join(CSV_DIR,\"test.csv\"))\n",
        "\n",
        "print(\"Train studies:\", len(train_df), \"Val studies:\", len(val_df), \"Test studies:\", len(test_df))\n",
        "\n",
        "# Dataset\n",
        "class RSNADataset(Dataset):\n",
        "    def __init__(self, df, image_root, transform=None, max_slices_per_study=None):\n",
        "        self.items = []\n",
        "        self.transform = transform\n",
        "        for _, row in df.iterrows():\n",
        "            uid = row[\"StudyInstanceUID\"]\n",
        "            label = int(row[\"patient_overall\"])\n",
        "            study_dir = os.path.join(image_root, uid)\n",
        "            if not os.path.isdir(study_dir):\n",
        "                continue\n",
        "            files = sorted([f for f in os.listdir(study_dir) if f.lower().endswith(('.png'))])\n",
        "            if len(files) == 0:\n",
        "                continue\n",
        "            # Pick slices\n",
        "            if max_slices_per_study:\n",
        "                mid = len(files)//2\n",
        "                half = max_slices_per_study//2\n",
        "                start = max(0, mid-half)\n",
        "                chosen = files[start:start+max_slices_per_study]\n",
        "            else:\n",
        "                chosen = files\n",
        "            for f in chosen:\n",
        "                self.items.append((os.path.join(study_dir,f), label))\n",
        "        random.shuffle(self.items)\n",
        "    def __len__(self):\n",
        "        return len(self.items)\n",
        "    def __getitem__(self, idx):\n",
        "        path,label = self.items[idx]\n",
        "        img = Image.open(path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, torch.tensor(label,dtype=torch.long)\n",
        "\n",
        "# Transforms\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(8),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "])\n",
        "eval_transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "])\n",
        "\n",
        "MAX_SLICES_PER_STUDY = 3\n",
        "\n",
        "train_ds = RSNADataset(train_df, IMAGE_ROOT, transform=train_transform, max_slices_per_study=MAX_SLICES_PER_STUDY)\n",
        "val_ds   = RSNADataset(val_df, IMAGE_ROOT, transform=eval_transform, max_slices_per_study=MAX_SLICES_PER_STUDY)\n",
        "test_ds  = RSNADataset(test_df, IMAGE_ROOT, transform=eval_transform, max_slices_per_study=MAX_SLICES_PER_STUDY)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
        "val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
        "test_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
        "\n",
        "print(\"Samples -> Train:\", len(train_ds), \"Val:\", len(val_ds), \"Test:\", len(test_ds))\n",
        "\n",
        "# Models\n",
        "\n",
        "# Simple CNN\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(16, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128*14*14, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# Build model\n",
        "def build_model(name):\n",
        "    if name==\"resnet18\":\n",
        "        m = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
        "        m.fc = nn.Linear(m.fc.in_features,2)\n",
        "    elif name==\"simple_cnn\":\n",
        "        m = SimpleCNN(num_classes=2)\n",
        "    else:\n",
        "        raise ValueError(name)\n",
        "    return m\n",
        "\n",
        "# Class weights\n",
        "def compute_class_weights(df_list):\n",
        "    all_labels = []\n",
        "    for df in df_list:\n",
        "        all_labels.extend(df[\"patient_overall\"].astype(int).tolist())\n",
        "    vals, counts = np.unique(all_labels, return_counts=True)\n",
        "    total = sum(counts)\n",
        "    weights = {k: total/(len(vals)*v) for k,v in zip(vals,counts)}\n",
        "    return torch.tensor([weights.get(0,1.0), weights.get(1,1.0)], dtype=torch.float).to(DEVICE)\n",
        "\n",
        "# Train one model\n",
        "def train_one_model(model_name):\n",
        "    model = build_model(model_name).to(DEVICE)\n",
        "    class_weights = compute_class_weights([train_df])\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2)\n",
        "    history = {\"train_loss\":[], \"val_loss\":[], \"train_acc\":[], \"val_acc\":[], \"val_auc\":[]}\n",
        "    best_auc = 0.0\n",
        "    best_wts = None\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        model.train()\n",
        "        preds_all, labels_all = [], []\n",
        "        running_loss = 0\n",
        "        for imgs, labels in tqdm(train_loader, leave=False):\n",
        "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()*imgs.size(0)\n",
        "            preds_all.extend(torch.argmax(outputs,1).cpu().numpy().tolist())\n",
        "            labels_all.extend(labels.cpu().numpy().tolist())\n",
        "        train_loss = running_loss/len(train_loader.dataset)\n",
        "        train_acc = accuracy_score(labels_all, preds_all)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_preds,val_labels,val_probs=[],[],[]\n",
        "        val_loss=0\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in val_loader:\n",
        "                imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
        "                outputs = model(imgs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()*imgs.size(0)\n",
        "                val_probs.extend(torch.softmax(outputs,1)[:,1].cpu().numpy())\n",
        "                val_preds.extend(torch.argmax(outputs,1).cpu().numpy())\n",
        "                val_labels.extend(labels.cpu().numpy())\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "        val_acc = accuracy_score(val_labels, val_preds)\n",
        "        val_auc = roc_auc_score(val_labels,val_probs) if len(np.unique(val_labels))>1 else 0\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "        history[\"val_loss\"].append(val_loss)\n",
        "        history[\"train_acc\"].append(train_acc)\n",
        "        history[\"val_acc\"].append(val_acc)\n",
        "        history[\"val_auc\"].append(val_auc)\n",
        "        scheduler.step(val_auc)\n",
        "        if val_auc>best_auc:\n",
        "            best_auc=val_auc\n",
        "            best_wts={k:v.cpu() for k,v in model.state_dict().items()}\n",
        "        print(f\"{model_name} Epoch {epoch+1}/{NUM_EPOCHS} - train_acc:{train_acc:.3f}, val_acc:{val_acc:.3f}, val_auc:{val_auc:.3f}\")\n",
        "    if best_wts:\n",
        "        model.load_state_dict(best_wts)\n",
        "    return model, history\n",
        "\n",
        "# Evaluate model\n",
        "def evaluate_model(model, loader):\n",
        "    model.eval()\n",
        "    preds, probs, labels = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for imgs, labs in loader:\n",
        "            imgs = imgs.to(DEVICE)\n",
        "            out = model(imgs)\n",
        "            probs.extend(torch.softmax(out,1)[:,1].cpu().numpy())\n",
        "            preds.extend(torch.argmax(out,1).cpu().numpy())\n",
        "            labels.extend(labs.numpy())\n",
        "    acc = accuracy_score(labels,preds)\n",
        "    prec = precision_score(labels,preds, zero_division=0)\n",
        "    rec = recall_score(labels,preds, zero_division=0)\n",
        "    f1 = f1_score(labels,preds, zero_division=0)\n",
        "    auc = roc_auc_score(labels,probs) if len(np.unique(labels))>1 else 0\n",
        "    cm = confusion_matrix(labels,preds)\n",
        "    fpr,tpr,_ = roc_curve(labels,probs) if len(np.unique(labels))>1 else (None,None,None)\n",
        "    return {\"acc\":acc,\"prec\":prec,\"rec\":rec,\"f1\":f1,\"auc\":auc,\"cm\":cm,\"fpr\":fpr,\"tpr\":tpr}\n",
        "\n",
        "# Train and Evaluate Two Models\n",
        "model_names = [\"simple_cnn\", \"resnet18\"]\n",
        "trained_models = {}\n",
        "histories = {}\n",
        "eval_results = {}\n",
        "\n",
        "for name in model_names:\n",
        "    print(f\"\\n==== Training {name} ====\")\n",
        "    m, h = train_one_model(name)\n",
        "    trained_models[name] = m\n",
        "    histories[name] = h\n",
        "    eval_results[name] = evaluate_model(m, val_loader)\n",
        "\n",
        "# Validation AUC plot\n",
        "plt.figure(figsize=(8,4))\n",
        "for name,h in histories.items():\n",
        "    plt.plot(h[\"val_auc\"], label=name)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Validation AUC\")\n",
        "plt.title(\"Validation AUC per Epoch\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Validation metrics comparison\n",
        "rows = []\n",
        "for name,res in eval_results.items():\n",
        "    rows.append({\n",
        "        \"model\": name,\n",
        "        \"acc\": res[\"acc\"],\n",
        "        \"prec\": res[\"prec\"],\n",
        "        \"rec\": res[\"rec\"],\n",
        "        \"f1\": res[\"f1\"],\n",
        "        \"auc\": res[\"auc\"]\n",
        "    })\n",
        "res_df = pd.DataFrame(rows).sort_values(\"auc\", ascending=False)\n",
        "print(res_df.round(3))\n",
        "sns.barplot(x=\"model\", y=\"auc\", data=res_df)\n",
        "plt.title(\"Validation AUC Comparison\")\n",
        "plt.ylim(0,1)\n",
        "plt.show()\n",
        "\n",
        "# Test set evaluation\n",
        "test_eval_all = {}\n",
        "for name, model in trained_models.items():\n",
        "    print(f\"\\nEvaluating {name} on Test Set...\")\n",
        "    test_eval_all[name] = evaluate_model(model, test_loader)\n",
        "\n",
        "# Test metrics comparison\n",
        "rows = []\n",
        "for name,res in test_eval_all.items():\n",
        "    rows.append({\n",
        "        \"model\": name,\n",
        "        \"acc\": res[\"acc\"],\n",
        "        \"prec\": res[\"prec\"],\n",
        "        \"rec\": res[\"rec\"],\n",
        "        \"f1\": res[\"f1\"],\n",
        "        \"auc\": res[\"auc\"]\n",
        "    })\n",
        "test_df = pd.DataFrame(rows).sort_values(\"auc\", ascending=False)\n",
        "print(\"\\nTest Set Performance:\")\n",
        "print(test_df.round(3))\n",
        "\n",
        "# Confusion matrices\n",
        "fig, axes = plt.subplots(1,len(test_eval_all), figsize=(5*len(test_eval_all),4))\n",
        "for i,(model_name,res) in enumerate(test_eval_all.items()):\n",
        "    ax = axes[i] if len(test_eval_all)>1 else axes\n",
        "    sns.heatmap(res[\"cm\"], annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax)\n",
        "    ax.set_title(f\"{model_name}\\nAcc: {res['acc']:.2f}, AUC: {res['auc']:.2f}\")\n",
        "    ax.set_xlabel(\"Predicted\")\n",
        "    ax.set_ylabel(\"Actual\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ROC curves\n",
        "plt.figure(figsize=(6,5))\n",
        "for name,res in test_eval_all.items():\n",
        "    if res.get(\"fpr\") is not None and res.get(\"tpr\") is not None:\n",
        "        plt.plot(res[\"fpr\"], res[\"tpr\"], label=f\"{name} (AUC={res['auc']:.2f})\")\n",
        "plt.plot([0,1],[0,1],'k--')\n",
        "plt.title(\"ROC Curves - Test Set\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Sample predictions from the best model\n",
        "best_model_name = test_df.iloc[0][\"model\"]\n",
        "best_model = trained_models[best_model_name]\n",
        "\n",
        "def show_samples(model, dataset, n_pos=2, n_neg=2):\n",
        "    model.eval()\n",
        "    pos_shown, neg_shown = 0,0\n",
        "    fig = plt.figure(figsize=(10,5))\n",
        "    for i in range(len(dataset)):\n",
        "        img,label = dataset[i]\n",
        "        with torch.no_grad():\n",
        "            out = model(img.unsqueeze(0).to(DEVICE))\n",
        "            pred = torch.argmax(out,1).item()\n",
        "        if pred==1 and pos_shown<n_pos:\n",
        "            ax = fig.add_subplot(1,n_pos+n_neg,pos_shown+1)\n",
        "            img_np = img.permute(1,2,0).cpu().numpy()\n",
        "            img_np = (img_np-img_np.min())/(img_np.max()-img_np.min()+1e-8)\n",
        "            ax.imshow(img_np)\n",
        "            ax.set_title(f\"Pred:Fract | True:{'Fract' if label==1 else 'Norm'}\")\n",
        "            ax.axis(\"off\")\n",
        "            pos_shown+=1\n",
        "        if pred==0 and neg_shown<n_neg:\n",
        "            ax = fig.add_subplot(1,n_pos+n_neg,n_pos+neg_shown+1)\n",
        "            img_np = img.permute(1,2,0).cpu().numpy()\n",
        "            img_np = (img_np-img_np.min())/(img_np.max()-img_np.min()+1e-8)\n",
        "            ax.imshow(img_np)\n",
        "            ax.set_title(f\"Pred:Norm | True:{'Fract' if label==1 else 'Norm'}\")\n",
        "            ax.axis(\"off\")\n",
        "            neg_shown+=1\n",
        "        if pos_shown>=n_pos and neg_shown>=n_neg:\n",
        "            break\n",
        "    plt.show()\n",
        "\n",
        "show_samples(best_model, test_ds)\n"
      ]
    }
  ]
}